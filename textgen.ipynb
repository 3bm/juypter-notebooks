{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "\n",
    "textfile = \"../data/hillary-clinton-emails-august-31-release_djvu.txt\"\n",
    "# textfile = '../data/shakespeare.txt'\n",
    "text = open(textfile,).read().decode('utf-8')\n",
    "counts = defaultdict(int)\n",
    "for char in text:\n",
    "    counts[char] += 1\n",
    "\n",
    "allowed_chars = 'abcdefghijklmnopqrstuvwxyz<>'\n",
    "allowed_chars += allowed_chars.upper()\n",
    "allowed_chars += '1234567890,.?!;:_@/\\'\" \\n'\n",
    "\n",
    "chars = [c for c, count in counts.iteritems() if count > 20 and c in allowed_chars]\n",
    "chars.append(None)\n",
    "char_lookup = {c: i for i, c in enumerate(chars)}\n",
    "\n",
    "seq_length = 40\n",
    "padding = [char_lookup[None]] * (seq_length-1)\n",
    "\n",
    "vec = np.array(padding + [char_lookup[c] for c in text if c in char_lookup] + padding)\n",
    "\n",
    "def vec_to_str(vec):\n",
    "    return u''.join([chars[i] for i in vec])\n",
    "\n",
    "print len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = tf.random_uniform([1], 0, len(vec) - seq_length - 1, dtype=tf.int32)\n",
    "random_seq = tf.slice(vec, start, [seq_length])\n",
    "next_chars = tf.slice(vec, start+seq_length, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JB@state.gov'; 'millscd@state.gov'; 'sul\n",
      "l\n"
     ]
    }
   ],
   "source": [
    "s, a = session.run([random_seq, next_chars])\n",
    "print vec_to_str(s)\n",
    "print vec_to_str(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Thread(Thread-4, started daemon 139754662254336)>,\n",
       " <Thread(Thread-5, started daemon 139754653861632)>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seq_batch, next_chars_batch = tf.train.batch([random_seq, next_chars], 256, num_threads=2)\n",
    "tf.train.start_queue_runners(sess=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_var(shape, stddev=0.1, weight_decay=0, name=None):\n",
    "    initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "    v = tf.Variable(initial, name=name)\n",
    "    if weight_decay > 0:\n",
    "        l2 = tf.nn.l2_loss(v) * weight_decay\n",
    "        tf.add_to_collection('losses', l2)\n",
    "    return v\n",
    "\n",
    "def leaky_relu(x, leak=0.2, name=\"lrelu\"):\n",
    "    with tf.variable_scope(name):\n",
    "        f1 = 0.5 * (1 + leak)\n",
    "        f2 = 0.5 * (1 - leak)\n",
    "        return f1 * x + f2 * abs(x)\n",
    "\n",
    "def relu(x):\n",
    "    # return tf.nn.relu(x)\n",
    "    return leaky_relu(x)\n",
    "\n",
    "def create_conv(input, out_channels, patch_size=5, stride=1, batch_norm=False, dropout=False):\n",
    "    in_channels = input.get_shape()[-1].value\n",
    "    w = weight_var([patch_size, patch_size, in_channels, out_channels])\n",
    "    b = weight_var([out_channels], stddev=0)\n",
    "    conv = tf.nn.conv2d(input, w, strides=[1,stride,stride,1], padding='SAME')\n",
    "    if batch_norm: conv = create_batch_norm(conv)\n",
    "    activation = relu(conv + b)\n",
    "    if dropout: activation = create_dropout(activation)\n",
    "    return activation\n",
    "    \n",
    "def text_conv(input, out_channels, patch_size=5, stride=1, dropout=False, pool_size=1):\n",
    "    in_channels = input.get_shape()[-1].value\n",
    "    w = weight_var([patch_size, in_channels, out_channels])\n",
    "    b = weight_var([out_channels], stddev=0)\n",
    "    conv = tf.nn.conv1d(input, w, stride=stride, padding='SAME')\n",
    "    activation = relu(conv + b)\n",
    "    # TODO: max_pooling\n",
    "    if dropout: activation = create_dropout(activation)\n",
    "    return activation\n",
    "\n",
    "def create_dropout(units):\n",
    "    return tf.nn.dropout(units, dropout)\n",
    "\n",
    "def create_fc(input, out_size):\n",
    "    # input_dropped = tf.nn.dropout(input, dropout_keep_prob)\n",
    "    in_size = input.get_shape()[-1].value\n",
    "    w = weight_var([in_size, out_size], weight_decay=0.004)\n",
    "    b = weight_var([out_size], weight_decay=0.004)\n",
    "    x = tf.matmul(input, w)\n",
    "    return relu(x + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_chars = tf.placeholder_with_default(random_seq_batch, [None, seq_length])\n",
    "dropout = tf.placeholder(tf.float32, name='dropout')\n",
    "is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "\n",
    "# build model:\n",
    "def rnn_model(prev_chars):\n",
    "    one_hot = tf.one_hot(prev_chars, len(chars), dtype=tf.float32)\n",
    "    \n",
    "    with tf.variable_scope('rnn', reuse=None):\n",
    "        \n",
    "        def cell(size, dropout=False):\n",
    "            c = tf.nn.rnn_cell.LSTMCell(size, state_is_tuple=True)\n",
    "            if dropout:\n",
    "                c = tf.nn.rnn_cell.DropoutWrapper(c, output_keep_prob=dropout)\n",
    "            return c\n",
    "        lstms = tf.nn.rnn_cell.MultiRNNCell([cell(512, True), cell(512, True)], state_is_tuple=True)\n",
    "        outputs, state = tf.nn.dynamic_rnn(lstms, one_hot, dtype=tf.float32)\n",
    "        last_outputs = tf.unstack(tf.transpose(outputs, [1, 0, 2]))[seq_length-1]\n",
    "        fc1 = create_fc(last_outputs, len(chars))\n",
    "    \n",
    "    return fc1\n",
    "    # return tf.nn.softmax(fc1)\n",
    "\n",
    "def conv_model(prev_chars):\n",
    "    one_hot = tf.one_hot(prev_chars, len(chars), dtype=tf.float32)\n",
    "    patches_and_channels = [(1,128), (3,32), (7,32)]\n",
    "    conv1 = tf.concat_v2([text_conv(one_hot, channels, patch) for patch, channels in patches_and_channels], axis=2)\n",
    "    # conv1 = tf.contrib.layers.batch_norm(conv1, is_training=is_training)\n",
    "    conv2 = tf.concat_v2([text_conv(conv1, channels, patch) for patch, channels in patches_and_channels], axis=2)\n",
    "    # conv2 = tf.contrib.layers.batch_norm(conv2, is_training=is_training)\n",
    "    out_size = sum(c for p,c in patches_and_channels) * seq_length\n",
    "    fc1 = create_fc(tf.reshape(conv2, [-1, out_size]), 1024)\n",
    "    fc2 = create_fc(fc1, len(chars))\n",
    "    return fc2\n",
    "\n",
    "def fc_model(prev_chars):\n",
    "    one_hot = tf.one_hot(prev_chars, len(chars), dtype=tf.float32)\n",
    "    fc1 = create_fc(tf.reshape(one_hot, [-1, seq_length * len(chars)]), 512)\n",
    "    fc2 = create_fc(fc1, 512)\n",
    "    fc2_d = tf.nn.dropout(fc2, dropout)\n",
    "    output = create_fc(fc2_d, len(chars))\n",
    "    return output\n",
    "    # return tf.nn.softmax(output)\n",
    "\n",
    "next_char_distribution = conv_model(prev_chars) # [batch, char_probs]\n",
    "# flatten char probabilities:\n",
    "target_chars = tf.reshape(next_chars_batch, [-1])\n",
    "# loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(next_char_distribution, target_chars))\n",
    "# probs_of_correct_words = tf.gather(tf.transpose(next_char_distribution), target_chars)\n",
    "# loss = tf.reduce_mean(-tf.log(probs_of_correct_words))\n",
    "loss = tf.reduce_sum(\n",
    "    tf.nn.seq2seq.sequence_loss_by_example(\n",
    "        [next_char_distribution], \n",
    "        [target_chars], \n",
    "        [tf.ones(tf.shape(target_chars))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learn_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "optimizer = tf.train.AdamOptimizer(learn_rate)\n",
    "global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "train_step = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "session.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will not save progress\n"
     ]
    }
   ],
   "source": [
    "save_path = None # 'models/textgen'\n",
    "import os\n",
    "\n",
    "saver = None\n",
    "if save_path:\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "    saver = tf.train.Saver()\n",
    "    ckpt = tf.train.get_checkpoint_state(save_path)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(session, ckpt.model_checkpoint_path)\n",
    "        print 'Restored from checkpoint', ckpt.model_checkpoint_path\n",
    "    else:\n",
    "        print 'Did not restore from checkpoint'\n",
    "else:\n",
    "    print 'Will not save progress'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4350, loss: 358.309265137\n",
      "Step: 4400, loss: 427.186950684\n",
      "Step: 4450, loss: 382.438323975\n",
      "Step: 4500, loss: 399.63885498\n",
      "Step: 4550, loss: 418.897583008\n",
      "Step: 4600, loss: 380.293426514\n",
      "Step: 4650, loss: 392.584381104\n",
      "Step: 4700, loss: 382.604309082\n",
      "Step: 4750, loss: 436.362060547\n",
      "Step: 4800, loss: 380.480895996\n",
      "Step: 4850, loss: 347.546112061\n",
      "Step: 4900, loss: 372.808288574\n",
      "Step: 4950, loss: 383.517211914\n",
      "Step: 5000, loss: 396.728118896\n",
      "Step: 5050, loss: 345.303039551\n",
      "Step: 5100, loss: 344.316925049\n",
      "Step: 5150, loss: 395.279968262\n",
      "Step: 5200, loss: 380.672546387\n",
      "Step: 5250, loss: 353.482635498\n",
      "Step: 5300, loss: 369.391906738\n",
      "Step: 5350, loss: 407.723815918\n",
      "Step: 5400, loss: 375.745666504\n",
      "Step: 5450, loss: 380.75793457\n",
      "Step: 5500, loss: 394.604278564\n",
      "Step: 5550, loss: 396.148345947\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-04b22dd3741a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     }\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mstep_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# print step_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep_\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    feed_dict = {\n",
    "        learn_rate: 0.001,\n",
    "        dropout: 0.7,\n",
    "        is_training: True\n",
    "    }\n",
    "    step_, loss_, _ = session.run([global_step, loss, train_step], feed_dict=feed_dict)\n",
    "    # print step_\n",
    "    if step_ % 50 == 0:\n",
    "        print 'Step: {}, loss: {}'.format(step_, loss_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "living movemy; Sullivan, Jacob J \n",
      "Subject: Re: MpP Bes Subject: 1 \n",
      "intergovicy Mandition groups an Chisle \n",
      "adminsts we polinios will fronis \n",
      "in the we are the Afthorid sure for. Ons yahm deal Davtyou from the leagenol, for the mest tho pize the \n",
      "my in are merils was on the Isman Depeal of the rourt Lead to from foreign afrounhyts the conniguats athed though power alstal the prould they the piNitely \n",
      "somenteryl for Prefaer majy. \n",
      "\n",
      "PDroisrn Daxtrdny otranqsest with Clem in the is cDn foll. Martic \n"
     ]
    }
   ],
   "source": [
    "def sample(length):\n",
    "    # generated = [char_lookup[None]] * seq_length\n",
    "    # the model doesn't learn how to start from an all-random vector, so feed it some real data\n",
    "    generated = [char_lookup[x] for x in \"JB@state.gov'; 'millscd@state.gov'; 'sul\"[:seq_length]]\n",
    "    for _ in range(length):\n",
    "        feed_dict = {\n",
    "            prev_chars: np.array([generated[-seq_length:]]),\n",
    "            dropout: 1,\n",
    "            is_training: False\n",
    "        }\n",
    "        # print np.array([generated[-seq_length:]])\n",
    "        distribution = session.run(tf.nn.softmax(next_char_distribution), feed_dict=feed_dict)[0]\n",
    "        # print 'distribution:', distribution\n",
    "        # print session.run(next_char_distribution, feed_dict=feed_dict)\n",
    "        char = np.random.choice(range(len(chars)), p=distribution)\n",
    "        generated.append(char)\n",
    "    return u''.join([chars[i] for i in generated[seq_length:] if chars[i] is not None])\n",
    "\n",
    "print sample(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
