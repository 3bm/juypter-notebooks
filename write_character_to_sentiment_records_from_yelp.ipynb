{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tokenizer import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_path = '/Users/nateparrott/Downloads/yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_review.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# counts = defaultdict(int)\n",
    "# review_lengths = []\n",
    "\n",
    "# reviews_path = '/Users/nateparrott/Downloads/yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_review.json'\n",
    "# for line in open(reviews_path):\n",
    "#     item = json.loads(line)\n",
    "#     if item['type'] == 'review':\n",
    "#         tokens = tokenize(item['text'])\n",
    "#         rating = item['stars']\n",
    "#         review_lengths.append(len(tokens))\n",
    "#         for tk in tokens: counts[tk] += 1\n",
    "#     if len(review_lengths) > 100 * 1000:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90th percentile review length: 271\n",
      "70th percentile review length: 149\n",
      "Vocab size: 9321\n"
     ]
    }
   ],
   "source": [
    "# review_lengths.sort()\n",
    "# print '90th percentile review length:', review_lengths[int(len(review_lengths) * 0.9)]\n",
    "# print '70th percentile review length:', review_lengths[int(len(review_lengths) * 0.7)]\n",
    "# vocab = [w for w, c in counts.iteritems() if c > 50]\n",
    "# print 'Vocab size:', len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_lengths = []\n",
    "\n",
    "for line in open(reviews_path):\n",
    "    item = json.loads(line)\n",
    "    if item['type'] == 'review':\n",
    "        char_lengths.append(len(item['text']))\n",
    "    if len(char_lengths) > 100 * 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90th percentile review length (chars): 1303\n",
      "70th percentile review length (chars): 713\n"
     ]
    }
   ],
   "source": [
    "char_lengths.sort()\n",
    "print '90th percentile review length (chars):', char_lengths[int(len(char_lengths) * 0.9)]\n",
    "print '70th percentile review length (chars):', char_lengths[int(len(char_lengths) * 0.7)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_review_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def pad(chars, length):\n",
    "    chars = chars[:min(len(chars), length)]\n",
    "    return chars + ' ' * (length - len(chars))\n",
    "\n",
    "def convert(filename, skip=0, count=None, out_path=None):\n",
    "    writer = tf.python_io.TFRecordWriter(out_path)\n",
    "    i = 0\n",
    "    for line in open(filename):\n",
    "        item = json.loads(line)\n",
    "        if item['type'] == 'review':\n",
    "            if i >= skip:\n",
    "                chars = item['text'].encode('ascii', 'ignore')\n",
    "                chars = pad(chars, max_review_len)\n",
    "                fdict = {'stars': _int64_feature(item['stars']), 'text': _bytes_feature(chars)}\n",
    "                example = tf.train.Example(features=tf.train.Features(feature=fdict))\n",
    "                writer.write(example.SerializeToString())\n",
    "            i += 1\n",
    "            if count is not None and i - skip > count: break\n",
    "    writer.close()\n",
    "\n",
    "test_size = 10 * 1000\n",
    "train_size = 10 * 1000\n",
    "convert(reviews_path, 0, test_size, 'yelp_test.tfrecords')\n",
    "convert(reviews_path, test_size, train_size, 'yelp_train.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
